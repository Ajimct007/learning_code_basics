{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3fb49e-8db9-40a2-ad40-111df22f4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfaddf1-d817-4d57-977e-2475f28a174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-05', '2017-01-05', '2017-01-05', '2017-01-05',\n",
       "               '2017-01-05', '2017-01-05'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we have the list of date of a same day, whcih we are converting them into pandas datetime format\n",
    "dates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05','20170105']\n",
    "pd.to_datetime(dates, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449e7246-aaa0-420e-9513-5052e2589dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-05 14:30:00', '2017-01-05 00:00:00',\n",
       "               '2017-01-05 14:30:00', '2017-01-05 00:00:00',\n",
       "               '2017-01-05 00:00:00', '2017-01-05 00:00:00'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## giving time\n",
    "dates = ['2017-01-05 2:30:00 pm', 'Jan 5, 2017', '01/05/2017 14:30:00', '2017.01.05', '2017/01/05','20170105']\n",
    "pd.to_datetime(dates, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5395faf-719f-440f-a04c-32f5a51a6849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-05 00:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for US -- mm/dd/yyyy\n",
    "## for europe -- dd/mm/yy\n",
    "pd.to_datetime('5/1/2017', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d51998-8dcf-48e6-972a-c81def4a669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-05 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can use our custom format also\n",
    "pd.to_datetime('5$1$2017', format='%d$%m$%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0028a930-c93c-4a12-9a0f-6e9720b0507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-05 14:30:00', '2017-01-05 00:00:00',\n",
       "               '2017-01-05 14:30:00', '2017-01-05 00:00:00',\n",
       "               '2017-01-05 00:00:00',                 'NaT'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what happens when we have the string values\n",
    "dates = ['2017-01-05 2:30:00 pm', 'Jan 5, 2017', '01/05/2017 14:30:00', '2017.01.05', '2017/01/05','abc']\n",
    "## by default the errors are set as raise, we have to change it to coerce\n",
    "pd.to_datetime(dates, format='mixed', errors='coerce') ## the string value converted as Not a Timestamp(NaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43fc7208-e279-4f22-bb5c-221bf408e28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-07-29 19:32:29'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for habdling the date in the format of Epoch (unix time) is number of seconds that have passed since Jan 1, 1970 00:00:00 UTC\n",
    "t = 1501356749 ### time till 2017 in seconds \n",
    "dt = pd.to_datetime([t], unit='s')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f11446e-160c-4724-9696-ed38c3599760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1501356749000000000], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert back to Epoch\n",
    "dt.view('int64') ## got epoch value with extra zeros for considering the nano seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
