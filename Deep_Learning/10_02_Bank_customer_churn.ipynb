{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7a9c7-a304-418b-b165-c3a40dafaee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e48e489-5076-45e6-8631-8c5c03b0942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a4d762-657e-41cd-ae06-a96b8b2ea1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>2284</td>\n",
       "      <td>15624633</td>\n",
       "      <td>Kibby</td>\n",
       "      <td>702</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>74989.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171014.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>4459</td>\n",
       "      <td>15585839</td>\n",
       "      <td>Niu</td>\n",
       "      <td>633</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>182258.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>15794413</td>\n",
       "      <td>Harris</td>\n",
       "      <td>416</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>878.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2726</td>\n",
       "      <td>15597951</td>\n",
       "      <td>Muir</td>\n",
       "      <td>471</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>114713.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36315.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>5038</td>\n",
       "      <td>15814923</td>\n",
       "      <td>Sullivan</td>\n",
       "      <td>606</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>128578.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>193878.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "2283       2284    15624633     Kibby          702    France    Male   45   \n",
       "4458       4459    15585839       Niu          633    France    Male   37   \n",
       "149         150    15794413    Harris          416    France    Male   32   \n",
       "2725       2726    15597951      Muir          471    France  Female   58   \n",
       "5037       5038    15814923  Sullivan          606     Spain    Male   38   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "2283       9   74989.58              1          1               1   \n",
       "4458       2       0.00              2          1               0   \n",
       "149        0       0.00              2          0               1   \n",
       "2725       4  114713.57              1          1               1   \n",
       "5037       7  128578.52              1          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "2283        171014.69       0  \n",
       "4458        182258.17       0  \n",
       "149            878.87       0  \n",
       "2725         36315.03       0  \n",
       "5037        193878.51       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"D:\\\\Data Science\\\\Code basics\\\\py-master\\\\DeepLearningML\\\\11_chrun_prediction\\\\Bank_churn.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d572142-a28c-40ed-9452-53b5c6790a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c4b8a1-b9a7-420d-b635-6eb26460d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f784de-1624-40eb-a4d5-d33525ee00a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1458f0b4-66f0-476f-b382-b935f24cc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "       for column in df:\n",
    "            if df[column].dtypes=='object':\n",
    "                print(f'{column}: {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f58fd31-bcdd-4f35-8fa0-c9d60295c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography: ['France' 'Spain' 'Germany']\n",
      "Gender: ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0213bacc-1187-4661-a2fc-2374c91c6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':1,'Male':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8476425-d9b3-44c2-a6bf-7858088e8784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
       "       'Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Geography'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95338fdc-0256-4e30-95a5-d4d3a235d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Gender                 int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_France        bool\n",
       "Geography_Germany       bool\n",
       "Geography_Spain         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f427fc6-d7f2-4b52-9330-f64614265776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Gender: [1 0]\n",
      "Age: [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure: [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance: [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts: [1 3 2 4]\n",
      "HasCrCard: [1 0]\n",
      "IsActiveMember: [1 0]\n",
      "EstimatedSalary: [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited: [1 0]\n",
      "Geography_France: [ True False]\n",
      "Geography_Germany: [False  True]\n",
      "Geography_Spain: [False  True]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3d92fd-9cf5-42b2-a3fd-3a2a87a080cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to scale CreditScore, Age, Tenure, EstimatedSalary\n",
    "\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Tenure', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6fc31a5-498b-4b28-a972-04db79757033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>0.684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130701.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296742</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>0.468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247733</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure    Balance  NumOfProducts  \\\n",
       "3156        0.684       1  0.310811     0.8  130701.29              1   \n",
       "3229        0.468       1  0.648649     0.5       0.00              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "3156          1               0         0.296742       1             False   \n",
       "3229          1               0         0.247733       1              True   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "3156               True            False  \n",
       "3229              False            False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bee18a3-0bac-427e-9e24-c5ecb33f7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae0dd78-f9bb-40b6-a1a8-57deb92ccb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f88f0944-5c30-4c4b-8976-af76200f03ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67317eeb-88fc-495b-a1cc-e6594c43cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>0.800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981478</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>0.476</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948551</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>0.846</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646869</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>0.402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.7</td>\n",
       "      <td>129717.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434670</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>0.602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421898</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>0.314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524</th>\n",
       "      <td>0.620</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.8</td>\n",
       "      <td>167181.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925815</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.6</td>\n",
       "      <td>98684.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668609</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567526</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure    Balance  NumOfProducts  \\\n",
       "7751        0.800       1  0.283784     0.6       0.00              2   \n",
       "4154        0.752       0  0.216216     0.3       0.00              2   \n",
       "3881        0.476       1  0.621622     0.3       0.00              1   \n",
       "9238        0.846       1  0.432432     0.4       0.00              2   \n",
       "5210        0.402       0  0.229730     0.7  129717.30              2   \n",
       "7487        0.602       1  0.513514     0.4       0.00              1   \n",
       "7542        0.314       1  0.216216     0.4       0.00              2   \n",
       "7524        0.620       1  0.297297     0.8  167181.01              1   \n",
       "9412        0.750       0  0.108108     0.6   98684.15              1   \n",
       "6377        0.684       0  0.202703     0.9       0.00              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "7751          0               0         0.096273             False   \n",
       "4154          1               0         0.981478              True   \n",
       "3881          1               1         0.948551              True   \n",
       "9238          1               0         0.646869              True   \n",
       "5210          0               0         0.434670              True   \n",
       "7487          0               0         0.421898              True   \n",
       "7542          1               1         0.303413             False   \n",
       "7524          1               1         0.925815              True   \n",
       "9412          0               0         0.668609              True   \n",
       "6377          1               0         0.567526              True   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "7751              False             True  \n",
       "4154              False            False  \n",
       "3881              False            False  \n",
       "9238              False            False  \n",
       "5210              False            False  \n",
       "7487              False            False  \n",
       "7542              False             True  \n",
       "7524              False            False  \n",
       "9412              False            False  \n",
       "6377              False            False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c4277c-f607-420f-ac60-82bd57642f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f560835c-13bd-4e0a-aa81-9a198b4e9dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# opt = keras.optimizers.Adam(learning_rate=0.01)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo_env\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# Build a model (ANN) in tensorflow/keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12,), activation='relu'), ## Input layer\n",
    "    keras.layers.Dense(8, activation='relu'), ## Hidden layer\n",
    "    keras.layers.Dense(1, activation='sigmoid') ## Output layer\n",
    "])\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dcd9b69-f3d9-4000-ba97-67b4f6d096a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 68.4616 - accuracy: 0.7090\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 45.6779 - accuracy: 0.7094\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 26.3614 - accuracy: 0.7188\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 24.3316 - accuracy: 0.7234\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 27.2141 - accuracy: 0.7190\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 24.7165 - accuracy: 0.7141\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 30.9146 - accuracy: 0.7168\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 23.4298 - accuracy: 0.7160\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 28.1883 - accuracy: 0.7063\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 24.3297 - accuracy: 0.7179\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 33.3669 - accuracy: 0.7113\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 18.8585 - accuracy: 0.7180\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 23.8804 - accuracy: 0.7169\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 17.5583 - accuracy: 0.7151\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 21.1368 - accuracy: 0.7100\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 22.0197 - accuracy: 0.7189\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 20.6621 - accuracy: 0.7155\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 25.3569 - accuracy: 0.7150\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 17.9219 - accuracy: 0.7131\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 16.2456 - accuracy: 0.7170\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 14.5100 - accuracy: 0.7191\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 18.4508 - accuracy: 0.7164\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 11.8271 - accuracy: 0.7155\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 25.7130 - accuracy: 0.7163\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 12.9639 - accuracy: 0.7150\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 18.3947 - accuracy: 0.7132\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 16.1142 - accuracy: 0.7184\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 15.1868 - accuracy: 0.7145\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 14.5704 - accuracy: 0.7194\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 12.3375 - accuracy: 0.7159\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12.0253 - accuracy: 0.7146\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 15.7050 - accuracy: 0.7179\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 13.1395 - accuracy: 0.7191\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 8.7822 - accuracy: 0.7168\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 8.4851 - accuracy: 0.7153\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 7.0331 - accuracy: 0.7143\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.7892 - accuracy: 0.7149\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 8.0176 - accuracy: 0.7139\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 9.8777 - accuracy: 0.7144\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 7.3732 - accuracy: 0.7119\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.7535 - accuracy: 0.7204\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.6325 - accuracy: 0.7128\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9856 - accuracy: 0.7174\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.2662 - accuracy: 0.7219\n",
      "Epoch 45/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.1564 - accuracy: 0.7211\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5670 - accuracy: 0.7179\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9699 - accuracy: 0.7197\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6102 - accuracy: 0.7153\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8247 - accuracy: 0.7204\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 2.3979 - accuracy: 0.7128\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1568 - accuracy: 0.7136\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 2.3568 - accuracy: 0.7240\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.7228 - accuracy: 0.7235\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.9931 - accuracy: 0.7204\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 2.1757 - accuracy: 0.7199\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.4082 - accuracy: 0.7314\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.0891 - accuracy: 0.7203\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.6935 - accuracy: 0.7219\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.1228 - accuracy: 0.7287\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.7451\n",
      "Epoch 61/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6368 - accuracy: 0.7381\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6086 - accuracy: 0.7505\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.7346\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5663 - accuracy: 0.7549\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5451 - accuracy: 0.7710\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.6925\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.7926\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.7960\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7960\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7960\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.7960\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7960\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4637 - accuracy: 0.7960\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.7960\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.7960\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.7960\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.7960\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.7960\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.7960\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.7960\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.7960\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.7960\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.7960\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.7960\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4602 - accuracy: 0.7960\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.7960\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.7960\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7960\n",
      "Epoch 89/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.7960\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7960\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7960\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4594 - accuracy: 0.7960\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4597 - accuracy: 0.7960\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4599 - accuracy: 0.7960\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.7960\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.7960\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.7960\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4596 - accuracy: 0.7960\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4595 - accuracy: 0.7960\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.7960\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4594 - accuracy: 0.7960\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4593 - accuracy: 0.7960\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.7960\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.7960\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4596 - accuracy: 0.7960\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4596 - accuracy: 0.7960\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.7960\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4596 - accuracy: 0.7960\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4592 - accuracy: 0.7960\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4588 - accuracy: 0.7960\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.7960\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4592 - accuracy: 0.7960\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.7960\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.7960\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.7960\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.7960\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4586 - accuracy: 0.7960\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.7960\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4586 - accuracy: 0.7960\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.7960\n",
      "Epoch 121/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.7960\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.7960\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.7960\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.7960\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.7960\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4563 - accuracy: 0.7960\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.7960\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4563 - accuracy: 0.7961\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4558 - accuracy: 0.7984\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.8001\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4547 - accuracy: 0.8008\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8005\n",
      "Epoch 133/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4546 - accuracy: 0.8004\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4542 - accuracy: 0.8006\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4542 - accuracy: 0.8004\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4540 - accuracy: 0.8006\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4540 - accuracy: 0.8006\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8006\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8006\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.8005\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7997\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.8005\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8002\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.7999\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.8005\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4535 - accuracy: 0.8005\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4533 - accuracy: 0.8002\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4537 - accuracy: 0.8002\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.8002\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8001\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4532 - accuracy: 0.8001\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8004\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8005\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8004\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.8006\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8002\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8004\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4529 - accuracy: 0.8008\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8005\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8004\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4526 - accuracy: 0.8005\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4526 - accuracy: 0.8006\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8004\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4528 - accuracy: 0.8005\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.8008\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.8005\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4526 - accuracy: 0.8006\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4520 - accuracy: 0.8009\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4525 - accuracy: 0.8004\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8002\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.8006\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4523 - accuracy: 0.8006\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4517 - accuracy: 0.8006\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.8005\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.8005\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.8008\n",
      "Epoch 177/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8006\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8011\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.8006\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.8005\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.7999\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8008\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4518 - accuracy: 0.8008\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8004\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8005\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.8005\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8004\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8005\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8002\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4517 - accuracy: 0.8001\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8005\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4516 - accuracy: 0.8002\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8005\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8010\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8008\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8005\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8008\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.8008\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8005\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8008\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8005\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.8005\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8006\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.8001\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8011\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8002\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8001\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8009\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8011\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8009\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8005\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.8008\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4510 - accuracy: 0.8005\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8008\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8010\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4507 - accuracy: 0.8011\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8010\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8012\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8011\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.8006\n",
      "Epoch 221/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8010\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8005\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8005\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8006\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8010\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8006\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.8010\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4510 - accuracy: 0.8006\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8009\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8008\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8012\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.8008\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8006\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.8010\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8009\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8009\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8010\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8012\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8012\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8006\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8011\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4500 - accuracy: 0.8012\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4499 - accuracy: 0.8008\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8010\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8009\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8010\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8011\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8004\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8010\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x243bec42250>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Ensure X_train and y_train are of the correct data type (float32 or float64)\n",
    "X_train = X_train.astype(np.float32)  # Cast X_train to float32\n",
    "y_train = y_train.astype(np.float32)  # Cast y_train to float32\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12,), activation='relu'),  # Input layer\n",
    "    keras.layers.Dense(8, activation='relu'), # Hidden layer\n",
    "    keras.layers.Dense(3, activation='relu'),# Hidden layer\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e3b655-2fed-40c4-8f02-bca6ab040f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4503896236419678, 0.8015000224113464]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure X_test and y_test are of the correct data type (float32)\n",
    "X_test = X_test.astype(np.float32)  # Cast X_test to float32\n",
    "y_test = y_test.astype(np.float32)  # Cast y_test to float32\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a15d3285-3495-46f3-9f3c-88446674dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0131494 ],\n",
       "       [0.26242304],\n",
       "       [0.26242304],\n",
       "       [0.26242304],\n",
       "       [0.26242304]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the prediction\n",
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fabd239-b85f-4f69-8551-825ac37bfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted values are in sigmoid output, we need to convert them in between 0 and 1\n",
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d120ca5f-fa13-4285-8d5a-5a4656ef7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "219b9d66-6e4f-4453-8ff8-865587f8df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7054    0.0\n",
       "442     0.0\n",
       "3954    0.0\n",
       "2288    0.0\n",
       "3196    0.0\n",
       "6178    0.0\n",
       "8351    0.0\n",
       "5658    1.0\n",
       "2065    0.0\n",
       "413     1.0\n",
       "Name: Exited, dtype: float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eacb88b1-e21d-4e4a-9ec3-a2f7e77e0fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89      1595\n",
      "         1.0       0.72      0.03      0.06       405\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.76      0.51      0.48      2000\n",
      "weighted avg       0.79      0.80      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "436bba36-5763-476b-85cd-246181002996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
