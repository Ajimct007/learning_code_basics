{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c357463-3c63-4687-9946-c66cfdc2aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa645dcd-5ad3-4ec2-8662-6982772716c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9238</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.3813</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.3834</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.3237</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3009</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1553</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "172  0.0180  0.0444  0.0476  0.0698  0.1615  0.0887  0.0596  0.1071  0.3175   \n",
       "15   0.0298  0.0615  0.0650  0.0921  0.1615  0.2294  0.2176  0.2033  0.1459   \n",
       "\n",
       "         9       10      11      12      13      14      15      16      17  \\\n",
       "172  0.2918  0.3273  0.3035  0.3033  0.2587  0.1682  0.1308  0.2803  0.4519   \n",
       "15   0.0852  0.2476  0.3645  0.2777  0.2826  0.3237  0.4335  0.5638  0.4555   \n",
       "\n",
       "         18      19      20      21      22      23      24      25      26  \\\n",
       "172  0.6641  0.7683  0.6960  0.4393  0.2432  0.2886  0.4974  0.8172  1.0000   \n",
       "15   0.4348  0.6433  0.3932  0.1989  0.3540  0.9165  0.9371  0.4620  0.2771   \n",
       "\n",
       "         27      28      29      30      31      32      33      34      35  \\\n",
       "172  0.9238  0.8519  0.7722  0.5772  0.5190  0.6824  0.6220  0.5054  0.3578   \n",
       "15   0.6613  0.8028  0.4200  0.5192  0.6962  0.5792  0.8889  0.7863  0.7133   \n",
       "\n",
       "         36      37      38      39      40      41      42      43      44  \\\n",
       "172  0.3809  0.3813  0.3359  0.2771  0.3648  0.3834  0.3453  0.2096  0.1031   \n",
       "15   0.7615  0.4401  0.3009  0.3163  0.2809  0.2898  0.0526  0.1867  0.1553   \n",
       "\n",
       "         45      46      47      48      49      50      51      52      53  \\\n",
       "172  0.0798  0.0701  0.0526  0.0241  0.0117  0.0122  0.0122  0.0114  0.0098   \n",
       "15   0.1633  0.1252  0.0748  0.0452  0.0064  0.0154  0.0031  0.0153  0.0071   \n",
       "\n",
       "         54      55      56      57      58      59 60  \n",
       "172  0.0027  0.0025  0.0026  0.0050  0.0073  0.0022  M  \n",
       "15   0.0212  0.0076  0.0152  0.0049  0.0200  0.0073  R  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"D:\\\\Data Science\\\\Code basics\\\\py-master\\\\deep-learning-keras-tf-tutorial-master\\\\13_dropout_layer\\\\sonar_dataset.csv\", header=None)\n",
    "# since we specified the header as 'None' it will assign the Integers as the column name\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3e77fc-1161-4b8a-8827-21a8508e3c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # 207 rows and 61 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1a4417-0bee-4a1e-aaea-74c0dbe4e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35577c5-d5c6-417f-a2e0-20e789d36ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # o to 59th are to be trained and 60th is the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4beff8d2-549e-41bf-b7c8-d5fa45b12493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26ba0064-48fd-4fbc-9fcf-14b719053256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X and Y\n",
    "X = df.drop(60, axis=1)\n",
    "y = df[60]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed475444-a2bf-4649-8315-d282dee5d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         R\n",
       "27    True\n",
       "139  False\n",
       "58    True\n",
       "80    True\n",
       "174  False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since y has the text data, we have to apply One Hot encoding\n",
    "y = pd.get_dummies(y, drop_first=True)\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8690047e-02f8-452f-bce0-d803e16efc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6495e4-f66f-435b-a999-0bde81f27e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (52, 60))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2684705-1bc6-41fa-91a5-e1c8aefd5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b68175-c0eb-4dc5-880f-d89c5c42e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 3ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.5513\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6410\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7372\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7372\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.8077\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7692\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8141\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8462\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.7885\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8654\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8974\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8654\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8846\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8974\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.9103\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.8974\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8718\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.8718\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.8910\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.9295\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9423\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9103\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9551\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9423\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8910\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9038\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9038\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9423\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9487\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9551\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9487\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9615\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9551\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9808\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9744\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9679\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9936\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9936\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9872\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9808\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9936\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9936\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9936\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9936\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9808\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9936\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9936\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x130de03b090>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'), # since we have 60 columns, we are setting the input layer as 60\n",
    "    keras.layers.Dense(30, activation='relu'), # Hidden layer\n",
    "    keras.layers.Dense(15, activation='relu'), # Hidden Layer\n",
    "    keras.layers.Dense(1, activation='sigmoid') # Output Layer\n",
    "])\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size = 8) # here we are using minibatch - size is 8\n",
    "\n",
    "# we got the accuracy as 1 -- seems like overfitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "099c0670-b9d4-4f1e-a16d-b3ed62ef2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9501 - accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9500966668128967, 0.7692307829856873]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the test data performance\n",
    "model.evaluate(X_test, y_test) # We got 0.7692 as our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b8dd79-f567-43f3-994f-7e909c2bcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "[8.6760473e-08 9.9341387e-01 9.8712122e-01 1.0749440e-05 9.9999684e-01\n",
      " 9.9813992e-01 6.6168569e-02 9.9999732e-01 6.0952389e-05 9.9999917e-01]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "## Making some predictions\n",
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26f4c3f1-1f87-4502-8a81-9aa62c27b8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         R\n",
       "186  False\n",
       "155  False\n",
       "165  False\n",
       "200  False\n",
       "58    True\n",
       "34    True\n",
       "151  False\n",
       "18    True\n",
       "202  False\n",
       "62    True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the y_test and y_predicted -- miss match\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5deead1-1ca1-411f-946c-14d34f292e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.85      0.79        27\n",
      "        True       0.81      0.68      0.74        25\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.78      0.77      0.77        52\n",
      "weighted avg       0.77      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da69cb62-bf18-4a9f-808f-d60d06c4d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 5ms/step - loss: 0.7689 - accuracy: 0.5641\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.8191 - accuracy: 0.4744\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7867 - accuracy: 0.4167\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.4872\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.5064\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6841 - accuracy: 0.5962\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7280 - accuracy: 0.5256\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.4936\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.4808\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.6026\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7157 - accuracy: 0.4615\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5064\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.5385\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6654 - accuracy: 0.6090\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.5962\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6875 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5385\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5641\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5128\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.6346\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6346\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6674 - accuracy: 0.6474\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6486 - accuracy: 0.6603\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6294 - accuracy: 0.6026\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6410\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6218\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.5897\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.6538\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.6538\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.6218\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6048 - accuracy: 0.6603\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.7115\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.6603\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5711 - accuracy: 0.6987\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6136 - accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.6987\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7244\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5648 - accuracy: 0.7436\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7308\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7436\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7564\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7564\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7436\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7692\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4798 - accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.7628\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7949\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7692\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.8141\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.8269\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.8013\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.8077\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7564\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7756\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7949\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7628\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.8013\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7949\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7885\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7885\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8141\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.8205\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.8141\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8269\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8462\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.8269\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7756\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.8013\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8526\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8590\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8077\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8526\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8269\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8974\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8397\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8462\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8462\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8397\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8205\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8205\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8462\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8526\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8718\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.9167\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3824 - accuracy: 0.8654\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8590\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8590\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8782\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8782\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8269\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3441 - accuracy: 0.8910\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.8910\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8974\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8526\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x130e3473090>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try a model with dropout layer\n",
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'), # Input layer\n",
    "    keras.layers.Dropout(0.5), # Mentioning the dropout -- will dropout 50% of the neurons\n",
    "    keras.layers.Dense(30, activation='relu'), # Hidden Layer\n",
    "    keras.layers.Dropout(0.5), # Mentioning the dropout -- will dropout 50% of the neurons\n",
    "    keras.layers.Dense(15, activation='relu'), # Hidden Layer\n",
    "    keras.layers.Dropout(0.5), # Mentioning the dropout -- will dropout 50% of the neurons\n",
    "    keras.layers.Dense(1, activation='sigmoid') # Output Layer\n",
    "])\n",
    "\n",
    "modeld.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modeld.fit(X_train, y_train, epochs=100, batch_size=8)\n",
    "\n",
    "# the accuracy reduced from 100 % to 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1324e0c-eedf-4de8-b976-fcd715c19b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4978 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4978223145008087, 0.75]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bde4aa0-5abd-42a5-863a-5438cdf57636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "[0.00658708 0.8908227  0.92217875 0.04267886 0.9997686  0.9575886\n",
      " 0.59737027 0.99993074 0.06072197 0.9998745 ]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeld.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a85065a-5292-459c-85aa-136d75621ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.85      0.78        27\n",
      "        True       0.80      0.64      0.71        25\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.76      0.75      0.75        52\n",
      "weighted avg       0.76      0.75      0.75        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5c894-7bcd-43dd-9875-3072ce2d08ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9510cbb-8478-40a5-8195-cf4052197b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555a938-8d38-42fc-85a6-e3f0660e5300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042fc66-cbce-440f-bfa8-c16c47087a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981fd38-f885-42b4-9507-4806c80e2732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
